Final EEG shape: (288, 25, 1125)
Final label shape: (288,)
Unique classes: [1 2 3 4]

Final EEG shape: this basically shows the dimensions of the data. so (288, 25, 1125) means there are 
288 trials, over 25 channels with the 1125 number of timepoints in each trial 
(how many samples in time for that trial)

Final label shape: this is the dimension of the array that holds the label numbers
so (288,) shows that it is a 1d array with 288 labels e.g [1,2,4,2,3...]


07/08/25

Final EEG shape: (288, 25, 1125)
Final label shape: (288,)
Unique classes: [1 2 3 4]
Filtered EEG shape: (144, 25, 1125)
Filtered labels: [1 2]

right now this is the output of the program along with the matplotlib graph
the filtered eeg shape shows that there are 144 labels instead of 288, meaning 144 labels were 3,4


---------Explanation of bandpass_8_30 and the csp_lda_baseline functions---------------------------

This is an explanation of everything after line 169 pretty much

We want a program that can look at short chunks of brain data (EEG) and say: “this trial is left‑hand” or “this trial is right‑hand.”

Things already done ---------
1. Loaded the raw recordings,
2. Cut them into trials (little windows of EEG),
3. Kept only the trials labeled left (1) or right (2),
4. Plotted a couple channels.

Next step ---------

Before we try any ML, we need to clean the signal so the motor information stands out. 
The simplest, most useful cleaning is a band‑pass filter around the motor bands (8–30 Hz). 
That’s it. 
Then we’ll try a quick baseline classifier to see if the data is separable.
Keep everything in the same file for now

If u don't know what a Band-pass filter is ---------

EEG contains lots of frequencies, most of which are noise for our task.
A band-pass filter keeps only the frequencies in a certain range and throws the rest away.
For motor imagery, the interesting brain rhythms are mostly:
Mu band: 8–12 Hz
Beta band: 13–30 Hz
So a band-pass filter 8–30 Hz means:
“Keep brain waves between 8 and 30 cycles per second, ignore everything slower or faster.”

If u don't know what a baseline classifier is ---------

A classifier is an algorithm that looks at the data and predicts the label (left or right).
A baseline classifier is just the first, simple model we use to check if our data is separable at all.
We don’t care if it’s the best model because we can just improve on it and compare to prev vrsns.
For EEG motor imagery, a common baseline is:
CSP (Common Spatial Patterns) : picks the best channel combinations for left vs right
LDA (Linear Discriminant Analysis) : a very simple prediction model

now we have a fully working pipeline. now i gotta make it stronger 

Better preprocessing + stronger model ---------

After slight optimisation 

What isnt actually needed right now

Both classifiers: keep either csp_lda_baseline or csp_svm_baseline. (SVM is stronger; LDA is fine as a quick check.)
Plotting helpers (get_channel_indices, plot_example_trial) are optional; keep them only if to visualize.
If not in UK/EU, switch the notch freqs to (60, 120) else its (50,100)

Everything else is serving a purpose:

loader/segmenter → builds (trials, channels, time)
left/right filter → keeps just the two classes
notch/bandpass/z-score → minimal but meaningful cleaning
CSP + classifier → the measurable baseline

Run this and share the new SVM accuracy; then we can decide whether to add ICA or ERD features next.

everything we have done so far up to this point --------------

Step 1 — Load & Segment Trials
EEG is stored as continuous signals. The dataset gives you the start time of each trial and its label.
The loader:
Reads .mat files from the dataset
Cuts the continuous EEG into 48-trial chunks per run
Produces an array shaped (trials, channels, timepoints)
Example: (288, 25, 1125) means 288 trials, 25 electrodes, 1125 samples (4.5 seconds) per trial.

Step 2 — Preprocessing (Cleaning)
EEG contains:
Low-frequency drift
High-frequency muscle noise
Powerline interference (50 Hz in UK/EU, 60 Hz in US)
Random amplitude differences
The code cleans it with:
filter_left_right() → keeps only trials with labels 1 or 2.
notch_filter() → removes mains hum at 50/60 Hz and its harmonic.
bandpass_8_30() → keeps only 8–30 Hz (mu/beta bands) where motor imagery lives.
zscore_per_channel() → standardizes each channel so all are on the same scale.
This step improves the signal-to-noise ratio so the classifier sees mostly relevant patterns.

Step 3 — Feature Extraction + Classification
Raw EEG is high-dimensional and noisy. We use:
CSP (Common Spatial Patterns) → finds the best combinations of channels that differ between left/right trials.
LDA or SVM → simple classifiers to test how separable the classes are.
We use cross-validation (train/test splits) to get a reliable estimate of accuracy.
The output CSP+SVM 5-fold accuracy: 0.78 ± 0.05 means:
On average, the model gets 78% correct
±0.05 means it varies about 5% between folds
This number is your baseline accuracy — the starting point for future improvements.

parameter explanation -----

n_components (CSP part)
CSP finds spatial filters — special combinations of EEG channels that maximize the difference between left and right conditions.
If you keep n_components = 6, that means:
Take the 3 most “left-like” filters and the 3 most “right-like” filters.
These become your features for classification.
Small n_components → fewer features, possibly missing useful patterns.
Large n_components → more features, but also more noise and risk of overfitting.
Sweeping n_components lets you test how many CSP features give the best accuracy.

C (SVM part)
In an SVM, C is the “regularization strength” parameter.
Controls the trade-off between:
Small C: wider margin, more tolerance for misclassified points (simpler model, less overfitting).
Large C: tries to classify every training point correctly (more complex model, can overfit).
Sweeping C tests whether the classifier should be stricter (big C) or more forgiving (small C).


BEST ACCURACY RESULT SO FAR 

nc=8, C=2.0 -> 0.708 ± 0.020

number of components (nc) is 8 meaning there are 4 most "left like" and 4 most "right like" combinations of EEG
channels that maximise the difference between the difference between the left and right conditions 

C value (C) is 2 meaning that there is more leniance for misclassification of L and R signals 
but there is less chance of overfitting 

------------------------------------------------------------------------------------------------------------------------
TO DO 

FIND THE BEST COV_EST THROUGH RUNNING THEM WITH EACH COV_EST TO FIND THE BEST ACCURACY

SO FAR 05/09/25 COV_EST = 'concat' gives me : 

CSP+LDA (nc=6, cov=concat): 0.694 ± 0.069 
CSP+SVM (nc=6, C=2.0, cov=concat): 0.659 ± 0.069
CSP+LDA (nc=8, cov=concat): 0.764 ± 0.093
CSP+SVM (nc=4, C=0.5, cov=concat): 0.736 ± 0.073
CSP+SVM (nc=4, C=1.0, cov=concat): 0.750 ± 0.085
CSP+SVM (nc=4, C=2.0, cov=concat): 0.764 ± 0.072
CSP+SVM (nc=4, C=4.0, cov=concat): 0.764 ± 0.060
CSP+SVM (nc=6, C=0.5, cov=concat): 0.723 ± 0.056
CSP+SVM (nc=6, C=1.0, cov=concat): 0.750 ± 0.050
CSP+SVM (nc=6, C=2.0, cov=concat): 0.785 ± 0.054
CSP+SVM (nc=6, C=4.0, cov=concat): 0.792 ± 0.042
CSP+SVM (nc=8, C=0.5, cov=concat): 0.799 ± 0.059
CSP+SVM (nc=8, C=1.0, cov=concat): 0.785 ± 0.079
CSP+SVM (nc=8, C=2.0, cov=concat): 0.799 ± 0.062
CSP+SVM (nc=8, C=4.0, cov=concat): 0.799 ± 0.054

SO FAR 05/09/25 COV_EST = 'oas' gives me : 

CSP+LDA (nc=6, cov=concat, reg=oas): 0.694 ± 0.069
CSP+SVM (nc=6, C=2.0, cov=concat, reg=oas): 0.659 ± 0.069
CSP+LDA (nc=8, cov=concat, reg=oas): 0.764 ± 0.093
CSP+SVM (nc=4, C=0.5, cov=concat, reg=oas): 0.736 ± 0.073
CSP+SVM (nc=4, C=1.0, cov=concat, reg=oas): 0.750 ± 0.085
CSP+SVM (nc=4, C=2.0, cov=concat, reg=oas): 0.778 ± 0.052
CSP+SVM (nc=4, C=4.0, cov=concat, reg=oas): 0.771 ± 0.064
CSP+SVM (nc=6, C=0.5, cov=concat, reg=oas): 0.723 ± 0.056
CSP+SVM (nc=6, C=1.0, cov=concat, reg=oas): 0.750 ± 0.050
CSP+SVM (nc=6, C=2.0, cov=concat, reg=oas): 0.785 ± 0.054
CSP+SVM (nc=6, C=4.0, cov=concat, reg=oas): 0.799 ± 0.044
CSP+SVM (nc=8, C=0.5, cov=concat, reg=oas): 0.799 ± 0.066
CSP+SVM (nc=8, C=1.0, cov=concat, reg=oas): 0.792 ± 0.068
CSP+SVM (nc=8, C=2.0, cov=concat, reg=oas): 0.806 ± 0.070
CSP+SVM (nc=8, C=4.0, cov=concat, reg=oas): 0.806 ± 0.063

SO FAR 05/09/25 COV_EST = 'ledoit_wolf' gives me : 

CSP+LDA (nc=6, cov=concat, reg=ledoit_wolf): 0.659 ± 0.095
CSP+SVM (nc=6, C=2.0, cov=concat, reg=ledoit_wolf): 0.624 ± 0.093
CSP+LDA (nc=8, cov=concat, reg=ledoit_wolf): 0.764 ± 0.093
CSP+SVM (nc=4, C=0.5, cov=concat, reg=ledoit_wolf): 0.736 ± 0.073
CSP+SVM (nc=4, C=1.0, cov=concat, reg=ledoit_wolf): 0.750 ± 0.085
CSP+SVM (nc=4, C=2.0, cov=concat, reg=ledoit_wolf): 0.778 ± 0.052
CSP+SVM (nc=4, C=4.0, cov=concat, reg=ledoit_wolf): 0.771 ± 0.064
CSP+SVM (nc=6, C=0.5, cov=concat, reg=ledoit_wolf): 0.723 ± 0.056
CSP+SVM (nc=6, C=1.0, cov=concat, reg=ledoit_wolf): 0.750 ± 0.050
CSP+SVM (nc=6, C=2.0, cov=concat, reg=ledoit_wolf): 0.785 ± 0.054
CSP+SVM (nc=6, C=4.0, cov=concat, reg=ledoit_wolf): 0.799 ± 0.044
CSP+SVM (nc=8, C=0.5, cov=concat, reg=ledoit_wolf): 0.806 ± 0.063
CSP+SVM (nc=8, C=1.0, cov=concat, reg=ledoit_wolf): 0.792 ± 0.068
CSP+SVM (nc=8, C=2.0, cov=concat, reg=ledoit_wolf): 0.813 ± 0.077
CSP+SVM (nc=8, C=4.0, cov=concat, reg=ledoit_wolf): 0.806 ± 0.063

------------------------------------------------------------------------------------------------------------------------


10/09/25

I have finally completed version 1 of the pipeline. 

Here is a recap of what load_bci_data.py does 

This is the training pipeline. It builds the final model.

Step-by-step:

1. 
Load raw EEG trials
Reads .mat dataset (e.g., A01T.mat).
Each run → multiple trials (4.5s long, 25 channels, 288 trials total).
Shapes:
(288, 25, 1125) = 288 trials × 25 EEG channels × 1125 samples.

2.
Filter only relevant classes
Keep Left-hand (1) and Right-hand (2) trials only.
Final dataset = 144 trials (72 Left, 72 Right).

3.
Preprocessing
Notch filter removes mains noise (50/60 Hz).
Bandpass filter (8–30 Hz) keeps motor cortex bands (mu/beta rhythms).
Z-scoring (optional) standardizes signals per channel.
Crop window: keep only [1.5s–4.0s] after cue (where motor imagery is strongest).

4.
Feature extraction with CSP
Common Spatial Patterns (CSP): learns spatial filters that maximize variance difference between classes.
Example: C3 channel stronger for right-hand, C4 for left-hand.

5.
Classifier training
Tried LDA and SVM with different parameters:
n_components (CSP filters kept) = [4, 6, 8].
C (SVM regularization) = [0.5, 1, 2, 4].
Found best combo → nc=8, C=2.0, cov=concat, reg=ledoit_wolf.

6.
Cross-validation
5-fold CV to estimate generalization.
Best accuracies ~80%.

7.
Final model training & saving
Train on all cropped trials.
Save everything (csp, svm, metadata) into models/csp_svm_final.joblib.
This file is the trained brainwave decoder.


Here is a recap of what test_model.py does

This is the evaluation pipeline. It checks how well the saved model works.

Step-by-step:

1.
Load saved model
Reads models/csp_svm_final.joblib.
Restores CSP filters, SVM classifier, and parameters.

2.
Reload & preprocess dataset
Same preprocessing as in training:
Load .mat file → filter left/right → notch filter → bandpass → crop [1.5s–4.0s].

3.
Predict on all trials
Transform EEG trials into CSP space.
Use SVM to predict Left vs Right.
Compute evaluation metrics
Accuracy: ~0.889 (89%).
Confusion Matrix:
[[61 11]   (Left correctly: 61, misclassified: 11)
 [ 5 67]]  (Right correctly: 67, misclassified: 5)

4.
Classification Report: precision, recall, F1-score for each class.
Plot confusion heatmap for easy visualization.

5.
Random trial sanity checks. this isnt really needed. just for random checking 
Pick 10 random trials.
Print:
True label
Predicted label
Probability distribution [P(left), P(right)].
Confirms the model is confident for most predictions.


next things to do : 

Generalization test → Run the model on another subject (A02T.mat) to see how well it transfers.